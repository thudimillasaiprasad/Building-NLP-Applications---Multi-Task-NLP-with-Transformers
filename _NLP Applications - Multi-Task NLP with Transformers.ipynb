{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import ipywidgets as widgets\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sentence classification - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_sentiment_model = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998732805252075}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nlp_sentiment_model('This is an excellent movie! Rellay nice plot and casting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9997850060462952}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment_model('This movie was not so good.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Classification - Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_token_class = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"LinkedIn was built to help professionals achieve more in their careers, and every day millions of people use our products to make connections, discover opportunities, and gain insights.\"\n",
    "        \"Our global reach means we get to make a direct impact on the world’s workforce in ways no other company can.\"\n",
    "        \"We’re much more than a digital resume -- we transform lives through innovative products and technology.\"\n",
    "        \"Every day, millions of posts, videos, and articles course through the LinkedIn feed, generating tens of thousands of comments every hour — and tens of millions more shares and likes.\"\n",
    "        \"We are looking for a research engineer/scientist to develop state of art vision algorithms to understand member posted visual content meaningfully.\"\n",
    "        \"You will be instrumental in improving the efficacy of communication and content exchange between millions of LinkedIn members by developing cutting edge content understanding and classification algorithms.\"\n",
    "        \"The understanding not only limited to extract features but to summarizing visual content, recognizing text and classifying it to the appropriate category. We own end to end stack from idea creation, POC, design to product deployment.\"\n",
    "        \"As part of a new and fast growing team of top-notch scientists and engineers, you will experience all the excitement and dynamism of a startup along with the scale and technology of a world-class enterprise.\"\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Link',\n",
       "  'score': 0.6165536642074585,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 1,\n",
       "  'start': 0,\n",
       "  'end': 4},\n",
       " {'word': '##ed',\n",
       "  'score': 0.6635887026786804,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 2,\n",
       "  'start': 4,\n",
       "  'end': 6},\n",
       " {'word': '##I',\n",
       "  'score': 0.8781384229660034,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 3,\n",
       "  'start': 6,\n",
       "  'end': 7},\n",
       " {'word': '##n',\n",
       "  'score': 0.937221348285675,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 4,\n",
       "  'start': 7,\n",
       "  'end': 8},\n",
       " {'word': 'Link',\n",
       "  'score': 0.6891728639602661,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 94,\n",
       "  'start': 466,\n",
       "  'end': 470},\n",
       " {'word': '##ed',\n",
       "  'score': 0.6991322636604309,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 95,\n",
       "  'start': 470,\n",
       "  'end': 472},\n",
       " {'word': '##I',\n",
       "  'score': 0.8263445496559143,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 96,\n",
       "  'start': 472,\n",
       "  'end': 473},\n",
       " {'word': '##n',\n",
       "  'score': 0.9524123668670654,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 97,\n",
       "  'start': 473,\n",
       "  'end': 474},\n",
       " {'word': 'Link',\n",
       "  'score': 0.9450805187225342,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 159,\n",
       "  'start': 834,\n",
       "  'end': 838},\n",
       " {'word': '##ed',\n",
       "  'score': 0.973464846611023,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 160,\n",
       "  'start': 838,\n",
       "  'end': 840},\n",
       " {'word': '##I',\n",
       "  'score': 0.9702901244163513,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 161,\n",
       "  'start': 840,\n",
       "  'end': 841},\n",
       " {'word': '##n',\n",
       "  'score': 0.9799590110778809,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 162,\n",
       "  'start': 841,\n",
       "  'end': 842}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_token_class(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_na = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "context= \" LinkedIn was built to help professionals achieve more in their careers, and every day millions of people use our products to make connections, discover opportunities, and gain insights. Our global reach means we get to make a direct impact on the world’s workforce in ways no other company can. We’re much more than a digital resume -- we transform lives through innovative products and technology.Every day, millions of posts, videos, and articles course through the LinkedIn feed, generating tens of thousands of comments every hour — and tens of millions more shares and likes.We are looking for a research engineer/scientist to develop state of art vision algorithms to understand member posted visual content meaningfully. You will be instrumental in improving the efficacy of communication and content exchange between millions of LinkedIn members by developing cutting edge content understanding and classification algorithms. The understanding not only limited to extract features but to summarizing visual content, recognizing text and classifying it to the appropriate category. We own end to end stack from idea creation, POC, design to product deployment.As part of a new and fast growing team of top-notch scientists and engineers, you will experience all the excitement and dynamism of a startup along with the scale and technology of a world-class enterprise.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.20314958691596985,\n",
       " 'start': 641,\n",
       " 'end': 671,\n",
       " 'answer': 'state of art vision algorithms'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_na(context = context, question = 'What is a research engineer?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.34431007504463196,\n",
       " 'start': 630,\n",
       " 'end': 727,\n",
       " 'answer': 'to develop state of art vision algorithms to understand member posted visual content meaningfully'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_na(context = context, question = 'What are the requirements for research scientist?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.06225580349564552,\n",
       " 'start': 869,\n",
       " 'end': 933,\n",
       " 'answer': 'cutting edge content understanding and classification algorithms'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_na(context = context, question = 'What are the work to be done for product development?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.37905916571617126,\n",
       " 'start': 1246,\n",
       " 'end': 1310,\n",
       " 'answer': 'you will experience all the excitement and dynamism of a startup'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_na(context = context, question = 'How we scale a world-class enterprise?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Text Generation - Mask Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_fill = pipeline('fill-mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'We are looking for answers',\n",
       "  'score': 0.06869515031576157,\n",
       "  'token': 5274,\n",
       "  'token_str': ' answers'},\n",
       " {'sequence': 'We are looking for solutions',\n",
       "  'score': 0.032083362340927124,\n",
       "  'token': 2643,\n",
       "  'token_str': ' solutions'},\n",
       " {'sequence': 'We are looking for volunteers',\n",
       "  'score': 0.028713900595903397,\n",
       "  'token': 4618,\n",
       "  'token_str': ' volunteers'},\n",
       " {'sequence': 'We are looking for submissions',\n",
       "  'score': 0.021905235946178436,\n",
       "  'token': 18219,\n",
       "  'token_str': ' submissions'},\n",
       " {'sequence': 'We are looking for recommendations',\n",
       "  'score': 0.02122603915631771,\n",
       "  'token': 4664,\n",
       "  'token_str': ' recommendations'}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_fill('We are looking for ' + nlp_fill.tokenizer.mask_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"LinkedIn was built to help professionals achieve more in their careers, and every day millions of people use our products to make connections, discover opportunities, and gain insights.\"\n",
    "        \"Our global reach means we get to make a direct impact on the world’s workforce in ways no other company can.\"\n",
    "        \"We’re much more than a digital resume -- we transform lives through innovative products and technology.\"\n",
    "        \"Every day, millions of posts, videos, and articles course through the LinkedIn feed, generating tens of thousands of comments every hour — and tens of millions more shares and likes.\"\n",
    "        \"We are looking for a research engineer/scientist to develop state of art vision algorithms to understand member posted visual content meaningfully.\"\n",
    "        \"You will be instrumental in improving the efficacy of communication and content exchange between millions of LinkedIn members by developing cutting edge content understanding and classification algorithms.\"\n",
    "        \"The understanding not only limited to extract features but to summarizing visual content, recognizing text and classifying it to the appropriate category. We own end to end stack from idea creation, POC, design to product deployment.\"\n",
    "        \"As part of a new and fast growing team of top-notch scientists and engineers, you will experience all the excitement and dynamism of a startup along with the scale and technology of a world-class enterprise.\"\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thudi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thudi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['linkedin built help professionals achieve careers every day millions people use products make connections discover opportunities gain insightsour global reach means get make direct impact worlds workforce ways company canwere much digital resume transform lives innovative products technologyevery day millions posts videos articles course linkedin feed generating tens thousands comments every hour tens millions shares likeswe looking research engineerscientist develop state art vision algorithms understand member posted visual content meaningfullyyou instrumental improving efficacy communication content exchange millions linkedin members developing cutting edge content understanding classification algorithmsthe understanding limited extract features summarizing visual content recognizing text classifying appropriate category end end stack idea creation poc design product deploymentas part new fast growing team topnotch scientists engineers experience excitement dynamism startup along scale technology worldclass enterprise'],\n",
       "      dtype='<U1036')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(corpus)\n",
    "norm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1,\n",
       "        1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(norm_corpus)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achieve</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>algorithmsthe</th>\n",
       "      <th>along</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>art</th>\n",
       "      <th>articles</th>\n",
       "      <th>built</th>\n",
       "      <th>canwere</th>\n",
       "      <th>careers</th>\n",
       "      <th>...</th>\n",
       "      <th>understand</th>\n",
       "      <th>understanding</th>\n",
       "      <th>use</th>\n",
       "      <th>videos</th>\n",
       "      <th>vision</th>\n",
       "      <th>visual</th>\n",
       "      <th>ways</th>\n",
       "      <th>workforce</th>\n",
       "      <th>worldclass</th>\n",
       "      <th>worlds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   achieve  algorithms  algorithmsthe  along  appropriate  art  articles  \\\n",
       "0        1           1              1      1            1    1         1   \n",
       "\n",
       "   built  canwere  careers  ...  understand  understanding  use  videos  \\\n",
       "0      1        1        1  ...           1              2    1       1   \n",
       "\n",
       "   vision  visual  ways  workforce  worldclass  worlds  \n",
       "0       1       2     1          1           1       1  \n",
       "\n",
       "[1 rows x 108 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all unique words in the corpus\n",
    "vocab = cv.get_feature_names()\n",
    "# show document feature vectors\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of N_Grams Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achieve careers</th>\n",
       "      <th>algorithms understand</th>\n",
       "      <th>algorithmsthe understanding</th>\n",
       "      <th>along scale</th>\n",
       "      <th>appropriate category</th>\n",
       "      <th>art vision</th>\n",
       "      <th>articles course</th>\n",
       "      <th>built help</th>\n",
       "      <th>canwere much</th>\n",
       "      <th>careers every</th>\n",
       "      <th>...</th>\n",
       "      <th>understanding classification</th>\n",
       "      <th>understanding limited</th>\n",
       "      <th>use products</th>\n",
       "      <th>videos articles</th>\n",
       "      <th>vision algorithms</th>\n",
       "      <th>visual content</th>\n",
       "      <th>ways company</th>\n",
       "      <th>workforce ways</th>\n",
       "      <th>worldclass enterprise</th>\n",
       "      <th>worlds workforce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   achieve careers  algorithms understand  algorithmsthe understanding  \\\n",
       "0                1                      1                            1   \n",
       "\n",
       "   along scale  appropriate category  art vision  articles course  built help  \\\n",
       "0            1                     1           1                1           1   \n",
       "\n",
       "   canwere much  careers every  ...  understanding classification  \\\n",
       "0             1              1  ...                             1   \n",
       "\n",
       "   understanding limited  use products  videos articles  vision algorithms  \\\n",
       "0                      1             1                1                  1   \n",
       "\n",
       "   visual content  ways company  workforce ways  worldclass enterprise  \\\n",
       "0               2             1               1                      1   \n",
       "\n",
       "   worlds workforce  \n",
       "0                 1  \n",
       "\n",
       "[1 rows x 121 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can set N_Gram Ranage from 1,2 to unigramsas well as bigrams and more.\n",
    "\n",
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(norm_corpus)\n",
    "\n",
    "bv_matrix = bv_matrix.toarray()\n",
    "vocab = bv.get_feature_names()\n",
    "pd.DataFrame(bv_matrix,columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets create TD-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achieve</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>algorithmsthe</th>\n",
       "      <th>along</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>art</th>\n",
       "      <th>articles</th>\n",
       "      <th>built</th>\n",
       "      <th>canwere</th>\n",
       "      <th>careers</th>\n",
       "      <th>...</th>\n",
       "      <th>understand</th>\n",
       "      <th>understanding</th>\n",
       "      <th>use</th>\n",
       "      <th>videos</th>\n",
       "      <th>vision</th>\n",
       "      <th>visual</th>\n",
       "      <th>ways</th>\n",
       "      <th>workforce</th>\n",
       "      <th>worldclass</th>\n",
       "      <th>worlds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   achieve  algorithms  algorithmsthe  along  appropriate   art  articles  \\\n",
       "0     0.08        0.08           0.08   0.08         0.08  0.08      0.08   \n",
       "\n",
       "   built  canwere  careers  ...  understand  understanding   use  videos  \\\n",
       "0   0.08     0.08     0.08  ...        0.08           0.15  0.08    0.08   \n",
       "\n",
       "   vision  visual  ways  workforce  worldclass  worlds  \n",
       "0    0.08    0.15  0.08       0.08        0.08    0.08  \n",
       "\n",
       "[1 rows x 108 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0.,max_df=1.,use_idf=True)\n",
    "tv_matrix = tv.fit_transform(norm_corpus)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "pd.DataFrame(np.round(tv_matrix,2),columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document Similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(tv_matrix)\n",
    "similarity_df=pd.DataFrame(similarity_matrix)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
